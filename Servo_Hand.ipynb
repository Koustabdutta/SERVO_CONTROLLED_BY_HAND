{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008571c8-71e1-417b-b601-587a834e4119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1755352746.993486   16553 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755352747.004208   16558 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n",
      "/home/rustom/anaconda3/envs/aienv/lib/python3.11/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import serial\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7)  # Allow 2 hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize serial connection to ESP32\n",
    "ser = serial.Serial('/dev/ttyUSB0', 115200)  # Replace with your ESP32 port\n",
    "time.sleep(2)  # Wait for connection\n",
    "\n",
    "# Finger landmark indices (MediaPipe)\n",
    "INDEX_FINGER_TIP = 8\n",
    "INDEX_FINGER_PIP = 6  # Proximal Interphalangeal Joint\n",
    "INDEX_FINGER_MCP = 5  # Metacarpophalangeal Joint\n",
    "WRIST = 0\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculate angle between three points (in degrees)\"\"\"\n",
    "    # Convert points to tuples if they're landmark objects\n",
    "    a = (a.x, a.y) if hasattr(a, 'x') else a\n",
    "    b = (b.x, b.y) if hasattr(b, 'x') else b\n",
    "    c = (c.x, c.y) if hasattr(c, 'x') else c\n",
    "    \n",
    "    # Calculate vectors\n",
    "    ba = (a[0] - b[0], a[1] - b[1])\n",
    "    bc = (c[0] - b[0], c[1] - b[1])\n",
    "    \n",
    "    # Calculate dot product and magnitudes\n",
    "    dot_product = ba[0]*bc[0] + ba[1]*bc[1]\n",
    "    mag_ba = math.sqrt(ba[0]**2 + ba[1]**2)\n",
    "    mag_bc = math.sqrt(bc[0]**2 + bc[1]**2)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if mag_ba * mag_bc < 0.001:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate angle in radians, then convert to degrees\n",
    "    angle_rad = math.acos(max(-1.0, min(1.0, dot_product / (mag_ba * mag_bc))))\n",
    "    angle_deg = math.degrees(angle_rad)\n",
    "    \n",
    "    return angle_deg\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "prev_left_angle = 90\n",
    "prev_right_angle = 90\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        continue\n",
    "        \n",
    "    img = cv2.flip(img, 1)  # Mirror image for more intuitive control\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(img_rgb)\n",
    "    \n",
    "    # Initialize servo angles to neutral position\n",
    "    left_servo_angle = 90\n",
    "    right_servo_angle = 90\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            # Get landmarks\n",
    "            lm = hand_landmarks.landmark\n",
    "            \n",
    "            # Draw hand landmarks\n",
    "            mp_draw.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "            # Determine handedness (left or right hand)\n",
    "            handedness = results.multi_handedness[hand_idx].classification[0].label\n",
    "            \n",
    "            # Calculate index finger angle\n",
    "            finger_angle = calculate_angle(\n",
    "                lm[INDEX_FINGER_MCP], \n",
    "                lm[INDEX_FINGER_PIP],\n",
    "                lm[INDEX_FINGER_TIP]\n",
    "            )\n",
    "            \n",
    "            # Map angle to servo range (0°-180°)\n",
    "            servo_angle = int(np.interp(finger_angle, [0, 90], [0, 180]))\n",
    "            \n",
    "            # Simple smoothing to reduce jitter\n",
    "            if handedness == \"Left\":\n",
    "                left_servo_angle = int(0.7 * servo_angle + 0.3 * prev_left_angle)\n",
    "                left_servo_angle = max(0, min(180, left_servo_angle))\n",
    "                prev_left_angle = left_servo_angle\n",
    "                \n",
    "                # Display left hand info\n",
    "                cv2.putText(img, f\"Left: {int(finger_angle)}deg -> Servo: {left_servo_angle}\", \n",
    "                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "                \n",
    "            elif handedness == \"Right\":\n",
    "                # Reverse mapping for right hand if needed\n",
    "                right_servo_angle = int(0.7 * servo_angle + 0.3 * prev_right_angle)\n",
    "                right_servo_angle = max(0, min(180, right_servo_angle))\n",
    "                prev_right_angle = right_servo_angle\n",
    "                \n",
    "                # Display right hand info\n",
    "                cv2.putText(img, f\"Right: {int(finger_angle)}deg -> Servo: {right_servo_angle}\", \n",
    "                            (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "    \n",
    "    # Send angles to ESP32\n",
    "    ser.write(f\"{left_servo_angle},{right_servo_angle}\\n\".encode())\n",
    "    \n",
    "    # Display instructions\n",
    "    cv2.putText(img, \"Left hand controls left servo\", (10, img.shape[0] - 80), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "    cv2.putText(img, \"Right hand controls right servo\", (10, img.shape[0] - 50), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "    cv2.putText(img, \"Press 'q' to quit\", (10, img.shape[0] - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"Dual-Hand Servo Control\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "ser.write(\"90,90\\n\".encode())  # Reset servos to neutral\n",
    "time.sleep(0.5)\n",
    "ser.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AI Env)",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
